{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Loan_ID Predicted_Loan_Status\n",
      "0   LP001002                     N\n",
      "1   LP001003                     Y\n",
      "2   LP001005                     Y\n",
      "3   LP001006                     Y\n",
      "4   LP001008                     Y\n",
      "5   LP001011                     Y\n",
      "6   LP001013                     Y\n",
      "7   LP001014                     N\n",
      "8   LP001018                     N\n",
      "9   LP001020                     Y\n",
      "10  LP001024                     Y\n",
      "11  LP001027                     Y\n",
      "12  LP001028                     N\n",
      "13  LP001029                     N\n",
      "14  LP001030                     Y\n",
      "15  LP001032                     N\n",
      "16  LP001034                     Y\n",
      "17  LP001036                     N\n",
      "18  LP001038                     N\n"
     ]
    }
   ],
   "source": [
    "#Random Forest Classifier for Loan Status Prediction\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Custom Label Encoder Class Definition\n",
    "class SafeLabelEncoder:\n",
    "    def __init__(self):\n",
    "        self.le = LabelEncoder()\n",
    "        self.classes_ = None\n",
    "\n",
    "    def fit_transform(self, X):\n",
    "        self.le.fit(X)\n",
    "        self.classes_ = set(self.le.classes_)\n",
    "        return self.le.transform(X)\n",
    "\n",
    "    def transform(self, X):\n",
    "        unseen = [x for x in X if x not in self.classes_]\n",
    "        return np.array([self.le.transform([x])[0] if x not in unseen else -1 for x in X])\n",
    "\n",
    "# Load data\n",
    "data = pd.read_csv('loan_data_set_Train.csv')  # Replace with the correct path to your data\n",
    "\n",
    "# Preprocessing\n",
    "# Handling missing data\n",
    "imputer = SimpleImputer(strategy='most_frequent')\n",
    "data_filled = pd.DataFrame(imputer.fit_transform(data), columns=data.columns)\n",
    "\n",
    "# Encoding categorical variables using SafeLabelEncoder\n",
    "label_encoders = {}\n",
    "for column in data_filled.columns:\n",
    "    if data_filled[column].dtype == 'object' and column not in ['Loan_ID', 'Loan_Status']:\n",
    "        sle = SafeLabelEncoder()\n",
    "        data_filled[column] = sle.fit_transform(data_filled[column])\n",
    "        label_encoders[column] = sle\n",
    "\n",
    "# Splitting data into features and target\n",
    "X = data_filled.drop(['Loan_ID', 'Loan_Status'], axis=1)\n",
    "y = data_filled['Loan_Status']\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Training the Random Forest Classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the Loan Status for a new candidate\n",
    "# Assuming you have new candidate data in 'new_data.csv'\n",
    "new_data = pd.read_csv('testdata.csv')\n",
    "new_data_filled = pd.DataFrame(imputer.transform(new_data), columns=new_data.columns)\n",
    "for column in new_data_filled.columns:\n",
    "    if column in label_encoders:\n",
    "        new_data_filled[column] = label_encoders[column].transform(new_data_filled[column])\n",
    "\n",
    "# Ensure that new_data_filled does not include 'Loan_ID' or 'Loan_Status' in the feature set\n",
    "new_X = new_data_filled.drop(['Loan_ID', 'Loan_Status'], axis=1, errors='ignore')\n",
    "\n",
    "# Prediction\n",
    "predicted_statuses = rf_classifier.predict(new_X)\n",
    "\n",
    "# Combine Loan_IDs with their predicted Loan_Status\n",
    "predictions = pd.DataFrame({\n",
    "    'Loan_ID': new_data_filled['Loan_ID'],\n",
    "    'Predicted_Loan_Status': predicted_statuses\n",
    "})\n",
    "\n",
    "print(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Loan_ID Predicted_Loan_Status\n",
      "0   LP001002                     Y\n",
      "1   LP001003                     Y\n",
      "2   LP001005                     Y\n",
      "3   LP001006                     Y\n",
      "4   LP001008                     Y\n",
      "5   LP001011                     Y\n",
      "6   LP001013                     Y\n",
      "7   LP001014                     N\n",
      "8   LP001018                     N\n",
      "9   LP001020                     Y\n",
      "10  LP001024                     Y\n",
      "11  LP001027                     Y\n",
      "12  LP001028                     N\n",
      "13  LP001029                     N\n",
      "14  LP001030                     Y\n",
      "15  LP001032                     Y\n",
      "16  LP001034                     Y\n",
      "17  LP001036                     N\n",
      "18  LP001038                     N\n"
     ]
    }
   ],
   "source": [
    "#Catboost Classifier for Loan Status Prediction\n",
    "\n",
    "# ===================== üì¶ IMPORT REQUIRED LIBRARIES ===================== #\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# ===================== üõ†Ô∏è SAFE LABEL ENCODER ===================== #\n",
    "class SafeLabelEncoder:\n",
    "    def __init__(self):\n",
    "        self.le = LabelEncoder()\n",
    "        self.classes_ = None\n",
    "\n",
    "    def fit_transform(self, X):\n",
    "        self.le.fit(X)\n",
    "        self.classes_ = set(self.le.classes_)\n",
    "        return self.le.transform(X)\n",
    "\n",
    "    def transform(self, X):\n",
    "        unseen = [x for x in X if x not in self.classes_]\n",
    "        return np.array([self.le.transform([x])[0] if x not in unseen else -1 for x in X])\n",
    "\n",
    "# ===================== üì• LOAD TRAINING DATA ===================== #\n",
    "data = pd.read_csv('loan_data_set_Train.csv')  # Update path if needed\n",
    "\n",
    "# ===================== üîß IMPUTE MISSING VALUES ===================== #\n",
    "imputer = SimpleImputer(strategy='most_frequent')\n",
    "data_filled = pd.DataFrame(imputer.fit_transform(data), columns=data.columns)\n",
    "\n",
    "# ===================== üîÅ ENCODE CATEGORICAL FEATURES ===================== #\n",
    "label_encoders = {}\n",
    "for column in data_filled.columns:\n",
    "    if data_filled[column].dtype == 'object' and column not in ['Loan_ID', 'Loan_Status']:\n",
    "        sle = SafeLabelEncoder()\n",
    "        data_filled[column] = sle.fit_transform(data_filled[column])\n",
    "        label_encoders[column] = sle\n",
    "\n",
    "# ===================== üßæ SPLIT FEATURES & TARGET ===================== #\n",
    "X = data_filled.drop(['Loan_ID', 'Loan_Status'], axis=1)\n",
    "y = data_filled['Loan_Status']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# ===================== üß† TRAIN CATBOOST CLASSIFIER ===================== #\n",
    "cb_classifier = CatBoostClassifier(verbose=0, random_state=42)\n",
    "cb_classifier.fit(X_train, y_train)\n",
    "\n",
    "# ===================== üß™ PREDICT NEW DATA ===================== #\n",
    "new_data = pd.read_csv('testdata.csv')\n",
    "new_data_filled = pd.DataFrame(imputer.transform(new_data), columns=new_data.columns)\n",
    "\n",
    "# Apply label encoders\n",
    "for column in new_data_filled.columns:\n",
    "    if column in label_encoders:\n",
    "        new_data_filled[column] = label_encoders[column].transform(new_data_filled[column])\n",
    "\n",
    "# Remove unused columns\n",
    "new_X = new_data_filled.drop(['Loan_ID', 'Loan_Status'], axis=1, errors='ignore')\n",
    "\n",
    "# Prediction\n",
    "predicted_statuses = cb_classifier.predict(new_X)\n",
    "\n",
    "# Output Results\n",
    "predictions = pd.DataFrame({\n",
    "    'Loan_ID': new_data_filled['Loan_ID'],\n",
    "    'Predicted_Loan_Status': predicted_statuses\n",
    "})\n",
    "\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 325, number of negative: 151\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001362 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 366\n",
      "[LightGBM] [Info] Number of data points in the train set: 476, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.682773 -> initscore=0.766545\n",
      "[LightGBM] [Info] Start training from score 0.766545\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "     Loan_ID Predicted_Loan_Status\n",
      "0   LP001002                     N\n",
      "1   LP001003                     N\n",
      "2   LP001005                     Y\n",
      "3   LP001006                     N\n",
      "4   LP001008                     Y\n",
      "5   LP001011                     Y\n",
      "6   LP001013                     Y\n",
      "7   LP001014                     N\n",
      "8   LP001018                     N\n",
      "9   LP001020                     Y\n",
      "10  LP001024                     Y\n",
      "11  LP001027                     Y\n",
      "12  LP001028                     N\n",
      "13  LP001029                     N\n",
      "14  LP001030                     Y\n",
      "15  LP001032                     N\n",
      "16  LP001034                     N\n",
      "17  LP001036                     N\n",
      "18  LP001038                     N\n"
     ]
    }
   ],
   "source": [
    "#LightGBM Classifier for Loan Status Prediction (Testing)\n",
    "# ===================== üì¶ IMPORT REQUIRED LIBRARIES ===================== #\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# ===================== üõ†Ô∏è SAFE LABEL ENCODER ===================== #\n",
    "class SafeLabelEncoder:\n",
    "    def __init__(self):\n",
    "        self.le = LabelEncoder()\n",
    "        self.classes_ = None\n",
    "\n",
    "    def fit_transform(self, X):\n",
    "        self.le.fit(X)\n",
    "        self.classes_ = set(self.le.classes_)\n",
    "        return self.le.transform(X)\n",
    "\n",
    "    def transform(self, X):\n",
    "        unseen = [x for x in X if x not in self.classes_]\n",
    "        return np.array([self.le.transform([x])[0] if x not in unseen else -1 for x in X])\n",
    "\n",
    "# ===================== üì• LOAD TRAINING DATA ===================== #\n",
    "data = pd.read_csv('loan_data_set_Train.csv')\n",
    "\n",
    "# ===================== üîß IMPUTE MISSING VALUES ===================== #\n",
    "imputer = SimpleImputer(strategy='most_frequent')\n",
    "data_filled = pd.DataFrame(imputer.fit_transform(data), columns=data.columns)\n",
    "\n",
    "# ===================== üîÅ ENCODE CATEGORICAL FEATURES ===================== #\n",
    "label_encoders = {}\n",
    "for column in data_filled.columns:\n",
    "    if data_filled[column].dtype == 'object' and column not in ['Loan_ID', 'Loan_Status']:\n",
    "        sle = SafeLabelEncoder()\n",
    "        data_filled[column] = sle.fit_transform(data_filled[column])\n",
    "        label_encoders[column] = sle\n",
    "\n",
    "# ===================== üßæ SPLIT FEATURES & TARGET ===================== #\n",
    "X = data_filled.drop(['Loan_ID', 'Loan_Status'], axis=1)\n",
    "y = data_filled['Loan_Status']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# ===================== üß† TRAIN LIGHTGBM CLASSIFIER ===================== #\n",
    "lgb_model = lgb.LGBMClassifier(random_state=42)\n",
    "lgb_model.fit(X_train, y_train)\n",
    "\n",
    "# ===================== üß™ PREDICT NEW DATA ===================== #\n",
    "new_data = pd.read_csv('testdata.csv')\n",
    "new_data_filled = pd.DataFrame(imputer.transform(new_data), columns=new_data.columns)\n",
    "\n",
    "for column in new_data_filled.columns:\n",
    "    if column in label_encoders:\n",
    "        new_data_filled[column] = label_encoders[column].transform(new_data_filled[column])\n",
    "\n",
    "new_X = new_data_filled.drop(['Loan_ID', 'Loan_Status'], axis=1, errors='ignore')\n",
    "\n",
    "predicted_statuses = lgb_model.predict(new_X)\n",
    "\n",
    "predictions = pd.DataFrame({\n",
    "    'Loan_ID': new_data_filled['Loan_ID'],\n",
    "    'Predicted_Loan_Status': predicted_statuses\n",
    "})\n",
    "\n",
    "print(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Loan_ID Predicted_Loan_Status\n",
      "0   LP001002                     N\n",
      "1   LP001003                     N\n",
      "2   LP001005                     Y\n",
      "3   LP001006                     Y\n",
      "4   LP001008                     Y\n",
      "5   LP001011                     Y\n",
      "6   LP001013                     Y\n",
      "7   LP001014                     N\n",
      "8   LP001018                     N\n",
      "9   LP001020                     Y\n",
      "10  LP001024                     Y\n",
      "11  LP001027                     Y\n",
      "12  LP001028                     N\n",
      "13  LP001029                     N\n",
      "14  LP001030                     Y\n",
      "15  LP001032                     N\n",
      "16  LP001034                     N\n",
      "17  LP001036                     N\n",
      "18  LP001038                     N\n"
     ]
    }
   ],
   "source": [
    "# XGBoost Classifier for Loan Status Prediction (Testing)\n",
    "# ===================== üì¶ IMPORT REQUIRED LIBRARIES ===================== #\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "\n",
    "# ===================== üõ°Ô∏è CUSTOM SAFE LABEL ENCODER ===================== #\n",
    "class SafeLabelEncoder:\n",
    "    def __init__(self):\n",
    "        self.le = LabelEncoder()\n",
    "        self.classes_ = None\n",
    "\n",
    "    def fit_transform(self, X):\n",
    "        self.le.fit(X)\n",
    "        self.classes_ = set(self.le.classes_)\n",
    "        return self.le.transform(X)\n",
    "\n",
    "    def transform(self, X):\n",
    "        return np.array([self.le.transform([x])[0] if x in self.classes_ else -1 for x in X])\n",
    "\n",
    "# ===================== üì• LOAD & PREPROCESS DATA ===================== #\n",
    "data = pd.read_csv('loan_data_set_Train.csv')  # Replace with actual path\n",
    "\n",
    "# Impute missing values\n",
    "imputer = SimpleImputer(strategy='most_frequent')\n",
    "data_filled = pd.DataFrame(imputer.fit_transform(data), columns=data.columns)\n",
    "\n",
    "# Encode categorical features (excluding Loan_ID and Loan_Status)\n",
    "label_encoders = {}\n",
    "for column in data_filled.columns:\n",
    "    if data_filled[column].dtype == 'object' and column not in ['Loan_ID', 'Loan_Status']:\n",
    "        sle = SafeLabelEncoder()\n",
    "        data_filled[column] = sle.fit_transform(data_filled[column])\n",
    "        label_encoders[column] = sle\n",
    "\n",
    "# Encode target variable (Loan_Status: Y/N ‚Üí 1/0)\n",
    "target_encoder = LabelEncoder()\n",
    "data_filled['Loan_Status'] = target_encoder.fit_transform(data_filled['Loan_Status'])\n",
    "\n",
    "# ===================== üßæ SPLIT DATA ===================== #\n",
    "X = data_filled.drop(['Loan_ID', 'Loan_Status'], axis=1)\n",
    "y = data_filled['Loan_Status']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# ===================== üß† TRAIN XGBOOST CLASSIFIER ===================== #\n",
    "xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# ===================== üß™ PREDICT ON NEW TEST DATA ===================== #\n",
    "new_data = pd.read_csv('testdata.csv')  # Replace with actual path\n",
    "\n",
    "# Impute missing values using same imputer\n",
    "new_data_filled = pd.DataFrame(imputer.transform(new_data), columns=new_data.columns)\n",
    "\n",
    "# Encode categorical features in new data\n",
    "for column in new_data_filled.columns:\n",
    "    if column in label_encoders:\n",
    "        new_data_filled[column] = label_encoders[column].transform(new_data_filled[column])\n",
    "\n",
    "# Prepare features for prediction\n",
    "new_X = new_data_filled.drop(['Loan_ID', 'Loan_Status'], axis=1, errors='ignore')\n",
    "\n",
    "# Predict and decode labels back to Y/N\n",
    "predicted_numeric = xgb_model.predict(new_X)\n",
    "predicted_statuses = target_encoder.inverse_transform(predicted_numeric)\n",
    "\n",
    "# Combine Loan_IDs with their predicted Loan_Status\n",
    "predictions = pd.DataFrame({\n",
    "    'Loan_ID': new_data_filled['Loan_ID'],\n",
    "    'Predicted_Loan_Status': predicted_statuses\n",
    "})\n",
    "\n",
    "# ===================== ‚úÖ DISPLAY RESULTS ===================== #\n",
    "print(predictions)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
